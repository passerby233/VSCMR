{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human evaluation script for story comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:54:57.215235Z",
     "start_time": "2019-04-12T13:54:56.937189Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import random\n",
    "from collections import Counter\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from rule_mining import utils as ut\n",
    "from rule_mining import config as cfg\n",
    "\n",
    "XE_pred_file = \"/home/lijiacheng/AREL-master/data/save/XE/XE_b3.json\"\n",
    "seman_XE_file = \"/home/lijiacheng/VSCMR/data/save/XE2_2/XE2-2_b1.json\"\n",
    "eval_list_file = \"eval_list.txt\"\n",
    "image_dir = os.path.join(cfg.dataset_path, 'images/test')\n",
    "\n",
    "XE_stories = ut.load_json(XE_pred_file)['output_stories']\n",
    "seman_XE_stories = ut.load_json(seman_XE_file)['output_stories']\n",
    "\n",
    "eval_list = []\n",
    "with open(eval_list_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        eval_list.append(int(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:54:57.239217Z",
     "start_time": "2019-04-12T13:54:57.217892Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_dict(stories):\n",
    "    story_dict = {}\n",
    "    for story in stories:\n",
    "        story_dict[int(story['story_id'])] = story\n",
    "    stories = story_dict\n",
    "    return stories\n",
    "XE_stories = convert_to_dict(XE_stories)\n",
    "seman_XE_stories = convert_to_dict(seman_XE_stories)\n",
    "XE_stories_keys = [int(idx) for idx in XE_stories.keys()]\n",
    "seman_XE_stories_keys = [int(idx) for idx in seman_XE_stories.keys()]\n",
    "\n",
    "def judge(human_label, seman_label):\n",
    "    if human_label == \"C\" or human_label == 'c': \n",
    "        score = 0\n",
    "    elif human_label == seman_label or human_label == seman_label.lower():\n",
    "        score = 1\n",
    "    else:\n",
    "        score = -1\n",
    "    return score\n",
    "\n",
    "def count(score_list):\n",
    "    result = {}\n",
    "    counter = Counter()\n",
    "    for tpl in score_list:\n",
    "        counter.update([tpl[0]])\n",
    "    ssum = counter[-1] + counter[0] + counter[1]\n",
    "    result['win'] = counter[1] / float(ssum)\n",
    "    result['lose'] = counter[-1] / float(ssum)\n",
    "    result['tie'] = counter[0] / float(ssum)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:55:04.781010Z",
     "start_time": "2019-04-12T13:54:57.242814Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tester_name = raw_input(\"Please input your name:\")\n",
    "relevance, expressiveness, correctness = [], [], []\n",
    "for idx,story_id in enumerate(eval_list[:1]):\n",
    "    if story_id in XE_stories_keys and story_id in seman_XE_stories_keys:\n",
    "        plt.figure(figsize=(17, 90))\n",
    "        for i in range(5):\n",
    "            base_name = XE_stories[story_id]['photo_sequence'][i] + \".jpg\"\n",
    "            filename = os.path.join(image_dir, base_name)\n",
    "            image = Image.open(filename)\n",
    "            plt.subplot(1, 5, 1+i)\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off') \n",
    "        plt.show()\n",
    "        print \"NO.\",idx,\"story_id:\",story_id,'\\n'\n",
    "        order = random.randint(0, 2)\n",
    "        if order == 1:\n",
    "            print \"A:\",XE_stories[story_id]['story_text_normalized'],'\\n'\n",
    "            print \"B:\",seman_XE_stories[story_id]['story_text_normalized'],'\\n'\n",
    "            scorer = judge(raw_input(\"Which story is more related to images:\"), 'B')\n",
    "            relevance.append((scorer, story_id))\n",
    "            scoree = judge(raw_input(\"Which story is more expressive:\"), 'B')\n",
    "            expressiveness.append((scoree, story_id))\n",
    "            scorec = judge(raw_input(\"Which story is more concrete:\"), 'B')\n",
    "            correctness.append((scorec, story_id))\n",
    "            #print scorer,scoree,scorec\n",
    "        else:\n",
    "            print \"A:\",seman_XE_stories[story_id]['story_text_normalized'],'\\n'\n",
    "            print \"B:\",XE_stories[story_id]['story_text_normalized'],'\\n'\n",
    "            scorer = judge(raw_input(\"Which story is more related to images:\"), 'A')\n",
    "            relevance.append((scorer, story_id))\n",
    "            scoree = judge(raw_input(\"Which story is more expressive:\"), 'A')\n",
    "            expressiveness.append((scoree, story_id))\n",
    "            scorec = judge(raw_input(\"Which story is more concrete:\"), 'A')\n",
    "            correctness.append((scorec, story_id))\n",
    "            #print scorer,scoree,scorec\n",
    "            \n",
    "test_result = {\"relevance\":count(relevance),\n",
    "              \"expressiveness\":count(expressiveness),\n",
    "              \"correctness\":count(correctness)}\n",
    "test_record = {\"relevance\":relevance,\n",
    "              \"expressiveness\":expressiveness,\n",
    "              \"correctness\":correctness,\n",
    "              \"result\":test_result}            \n",
    "\n",
    "print(test_result)\n",
    "save_dir = os.path.join(cfg.proj_dir, 'data/eval/')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "ut.save_json(os.path.join(save_dir, tester_name +'.json'), test_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
