{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T14:13:18.773784Z",
     "start_time": "2019-04-12T14:12:55.222982Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from rule_mining import utils as ut\n",
    "from rule_mining import config as cfg\n",
    "from rule_mining.detector import VsDetector\n",
    "\n",
    "im_keep = 10\n",
    "im_range = 2048\n",
    "mode = 'test'\n",
    "\n",
    "trans_info_file = os.path.join(cfg.rule_data_path, '{}_trans_info.npz'.format(mode))\n",
    "annofile = os.path.join(cfg.dataset_path, 'annotations/sis/{}.story-in-sequence.json'.format(mode))\n",
    "\n",
    "annotations = ut.load_json(annofile)['annotations']\n",
    "trans_info = ut.load_npz_dict(trans_info_file)\n",
    "id2words = ut.load_json(cfg.txtdata_file)['id2words']\n",
    "\n",
    "# create a detector from a rule_file\n",
    "rule_file = os.path.join(cfg.rule_data_path, 'rules03_0.6.npz')\n",
    "detector = VsDetector(rule_file, id2words)\n",
    "print rule_file\n",
    "print \"rules_num = %d, categories_kinds = %d\" % (detector.rules_num, detector.elem_kinds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T14:13:23.454731Z",
     "start_time": "2019-04-12T14:13:18.778002Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from scipy.misc import imread\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "class MyResnet(nn.Module):\n",
    "    def __init__(self, resnet):\n",
    "        super(MyResnet, self).__init__()\n",
    "        self.resnet = resnet\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.unsqueeze(0)\n",
    "\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "        feature_map = x\n",
    "        feature = x.mean(3).mean(2).squeeze()\n",
    "\n",
    "        return feature_map, feature\n",
    "    \n",
    "preprocess = transforms.Compose([\n",
    "    # trn.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model = torchvision.models.resnet152(pretrained=True)\n",
    "resnet = MyResnet(model)\n",
    "resnet.cuda()\n",
    "resnet.eval()\n",
    "print(\"resnet loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get rules of specifical concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T14:13:26.775150Z",
     "start_time": "2019-04-12T14:13:23.458697Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_dir = os.path.join(cfg.feature_dir, '{}/'.format(mode))\n",
    "img_id_list = ['6828584731']\n",
    "for img_id in img_id_list:\n",
    "    img_file = os.path.join(cfg.dataset_path, 'images',mode,\"{}.jpg\".format(img_id))\n",
    "    if not os.path.exists(img_file):\n",
    "        img_file = os.path.join(cfg.dataset_path,\"images\",mode,\"{}.png\".format(img_id))\n",
    "    im_trans = trans_info['id2trans'][img_id][:10]\n",
    "    semantic_words = detector.detect(im_trans)\n",
    "    semantic_words = [word.encode('utf-8') for word in semantic_words]\n",
    "    try:\n",
    "        img = Image.open(img_file)\n",
    "    except:\n",
    "        print(\"image %s not found\" % img_id)\n",
    "        continue\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    plt.imshow(img) \n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    print(semantic_words)\n",
    "    for rule, elem_set in detector.rules.items():\n",
    "        if detector.pattern_to_set[rule].issubset(im_trans):\n",
    "            ve_words = [detector.id2words[str(int(idx)-detector.imrange)] for idx in elem_set]\n",
    "            if 'pumpkin' in ve_words:\n",
    "                print detector.pattern_to_set[rule],ve_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load image and get feature map for specifical filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T14:13:26.852179Z",
     "start_time": "2019-04-12T14:13:26.780066Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#img_id = '6828584731' #pumpkin\n",
    "filters = [1484, 853, 646, 1287, 458] \n",
    "\n",
    "image = imread(img_file)\n",
    "image_v = image.astype('float32') / 255.0\n",
    "image_v = torch.from_numpy(image_v.transpose([2, 0, 1]))\n",
    "image_v = Variable(preprocess(image_v), volatile=True).cuda()\n",
    "feature_map, feature= resnet(image_v)\n",
    "img_feature_map = feature_map.data.cpu().float().numpy()\n",
    "#img_feature = feature.data.cpu().float().numpy()\n",
    "image = image.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output feature map and picture with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T14:13:28.331170Z",
     "start_time": "2019-04-12T14:13:26.856378Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print image.shape, img_feature_map.shape\n",
    "for filter_id in filters:\n",
    "    #print img_feature_map[0,filter_id]\n",
    "    print(\"filter_id%d\" %filter_id)\n",
    "    f = img_feature_map[0,filter_id]\n",
    "    \n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    plt.imshow(f)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    print image.shape,f.shape\n",
    "    zoom_factor = (image.shape[0]/f.shape[0], image.shape[1]/f.shape[1])\n",
    "    f = zoom(f, zoom_factor, order=1)\n",
    "    f = f[:, :, np.newaxis]\n",
    "    image_mask = np.concatenate((f, f, f), axis=2)\n",
    "    image_mask = np.minimum(image_mask, 1)\n",
    "    image_with_mask = image * image_mask\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    plt.imshow(image_with_mask)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
